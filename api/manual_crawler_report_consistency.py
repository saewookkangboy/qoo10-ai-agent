"""
í¬ë¡¤ëŸ¬ ë° ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ê°„ì˜ ë°ì´í„° ì¼ì¹˜ ì—¬ë¶€ í…ŒìŠ¤íŠ¸
"""
import asyncio
import json
import sys
from typing import Dict, Any
from datetime import datetime

# ë¡œê¹… ì„¤ì • (crawlerì™€ ë™ì¼í•œ ê·œì¹™ ì‚¬ìš©)
# - CRAWLER_DEBUG_LOG_PATH: íŒŒì¼ ê²½ë¡œ ì§€ì • (ê¸°ë³¸: í”„ë¡œì íŠ¸ ë£¨íŠ¸/.cursor/debug.log)
import os
from pathlib import Path

_default_log_path = Path(__file__).resolve().parents[1].parent / ".cursor" / "debug.log"
LOG_PATH = Path(os.getenv("CRAWLER_DEBUG_LOG_PATH", str(_default_log_path)))
LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
def log_debug(session_id: str, run_id: str, hypothesis_id: str, location: str, message: str, data: Dict[str, Any] = None):
    """ë””ë²„ê·¸ ë¡œê·¸ ì‘ì„±"""
    try:
        log_entry = {
            "sessionId": session_id,
            "runId": run_id,
            "hypothesisId": hypothesis_id,
            "location": location,
            "message": message,
            "data": data or {},
            "timestamp": int(datetime.now().timestamp() * 1000)
        }
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"Logging error: {e}")

async def main():
    test_url = "https://www.qoo10.jp/g/1093098159"
    session_id = "debug-session"
    run_id = "run1"
    
    print("=" * 80)
    print("í¬ë¡¤ëŸ¬ ë° ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ê°„ì˜ ë°ì´í„° ì¼ì¹˜ ì—¬ë¶€ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print(f"í…ŒìŠ¤íŠ¸ URL: {test_url}\n")
    
    # ê°€ì„¤ ì •ì˜
    hypotheses = {
        "H1": "í¬ë¡¤ëŸ¬ê°€ ìˆ˜ì§‘í•œ ë°ì´í„°ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ê³¼ì •ì—ì„œ ì†ì‹¤ë¨",
        "H2": "analysis_result êµ¬ì¡°ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ì— ì „ë‹¬ë  ë•Œ ë¶ˆì¼ì¹˜ ë°œìƒ",
        "H3": "ë¦¬í¬íŠ¸ ìƒì„± ì‹œ í¬ë¡¤ëŸ¬ ë°ì´í„°ì™€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê²°ê³¼ê°€ ë§¤í•‘ë˜ì§€ ì•ŠìŒ",
        "H4": "ë°ì´í„° ê²€ì¦ ê³¼ì •ì—ì„œ ìœ íš¨í•œ ë°ì´í„°ê°€ ì œê±°ë¨",
        "H5": "ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ê²°ê³¼ê°€ ë¦¬í¬íŠ¸ì— ë°˜ì˜ë˜ì§€ ì•ŠìŒ"
    }
    
    log_debug(session_id, run_id, "INIT", "test_crawler_report_consistency.py:main", "í…ŒìŠ¤íŠ¸ ì‹œì‘", {
        "url": test_url,
        "hypotheses": hypotheses
    })
    
    try:
        from services.crawler import Qoo10Crawler
        from services.analyzer import ProductAnalyzer
        from services.checklist_evaluator import ChecklistEvaluator
        from services.report_generator import ReportGenerator
        
        # ========== 1ë‹¨ê³„: í¬ë¡¤ë§ ==========
        print("[1ë‹¨ê³„] í¬ë¡¤ë§ ì¤‘...")
        crawler = Qoo10Crawler()
        log_debug(session_id, run_id, "H1", "test_crawler_report_consistency.py:main", "í¬ë¡¤ë§ ì‹œì‘", {"url": test_url})
        
        product_data = await crawler.crawl_product(test_url, use_playwright=True)
        
        # í¬ë¡¤ëŸ¬ ë°ì´í„° í•µì‹¬ í•„ë“œ ë¡œê¹…
        log_debug(session_id, run_id, "H1", "test_crawler_report_consistency.py:main", "í¬ë¡¤ë§ ì™„ë£Œ - ì›ë³¸ ë°ì´í„°", {
            "product_name": product_data.get("product_name", ""),
            "has_price": bool(product_data.get("price")),
            "price_sale": product_data.get("price", {}).get("sale_price"),
            "price_original": product_data.get("price", {}).get("original_price"),
            "has_reviews": bool(product_data.get("reviews")),
            "review_count": product_data.get("reviews", {}).get("review_count"),
            "review_rating": product_data.get("reviews", {}).get("rating"),
            "has_description": bool(product_data.get("description")),
            "description_length": len(product_data.get("description", "")),
            "has_images": bool(product_data.get("images")),
            "image_count": len(product_data.get("images", {}).get("detail_images", [])),
            "has_qpoint": bool(product_data.get("qpoint_info")),
            "qpoint_max": product_data.get("qpoint_info", {}).get("max_points"),
            "has_coupon": bool(product_data.get("coupon_info")),
            "has_shipping": bool(product_data.get("shipping_info")),
            "return_policy": product_data.get("shipping_info", {}).get("return_policy"),
            "has_category": bool(product_data.get("category")),
            "has_brand": bool(product_data.get("brand")),
            "has_search_keywords": bool(product_data.get("search_keywords")),
            "all_keys": list(product_data.keys())
        })
        
        print(f"  âœ“ í¬ë¡¤ë§ ì™„ë£Œ: {len(product_data)}ê°œ í•„ë“œ")
        
        # ========== 2ë‹¨ê³„: ë¶„ì„ ==========
        print("\n[2ë‹¨ê³„] ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        analyzer = ProductAnalyzer()
        log_debug(session_id, run_id, "H2", "test_crawler_report_consistency.py:main", "ë¶„ì„ ì‹œì‘", {
            "product_name": product_data.get("product_name", "")[:50]
        })
        
        analysis_result = await analyzer.analyze(product_data)
        
        # analysis_result êµ¬ì¡° ë¡œê¹…
        log_debug(session_id, run_id, "H2", "test_crawler_report_consistency.py:main", "ë¶„ì„ ì™„ë£Œ - analysis_result êµ¬ì¡°", {
            "has_overall_score": bool(analysis_result.get("overall_score")),
            "overall_score": analysis_result.get("overall_score"),
            "has_image_analysis": bool(analysis_result.get("image_analysis")),
            "image_score": analysis_result.get("image_analysis", {}).get("score"),
            "has_price_analysis": bool(analysis_result.get("price_analysis")),
            "price_score": analysis_result.get("price_analysis", {}).get("score"),
            "price_sale": analysis_result.get("price_analysis", {}).get("sale_price"),
            "price_original": analysis_result.get("price_analysis", {}).get("original_price"),
            "has_review_analysis": bool(analysis_result.get("review_analysis")),
            "review_score": analysis_result.get("review_analysis", {}).get("score"),
            "review_count": analysis_result.get("review_analysis", {}).get("review_count"),
            "review_rating": analysis_result.get("review_analysis", {}).get("rating"),
            "has_description_analysis": bool(analysis_result.get("description_analysis")),
            "description_score": analysis_result.get("description_analysis", {}).get("score"),
            "has_seo_analysis": bool(analysis_result.get("seo_analysis")),
            "seo_score": analysis_result.get("seo_analysis", {}).get("score"),
            "all_keys": list(analysis_result.keys())
        })
        
        print(f"  âœ“ ë¶„ì„ ì™„ë£Œ: ì¢…í•© ì ìˆ˜ {analysis_result.get('overall_score', 0)}ì ")
        
        # ========== 3ë‹¨ê³„: ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ==========
        print("\n[3ë‹¨ê³„] ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ì¤‘...")
        checklist_evaluator = ChecklistEvaluator()
        log_debug(session_id, run_id, "H3", "test_crawler_report_consistency.py:main", "ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ì‹œì‘", {
            "product_data_keys": list(product_data.keys()),
            "analysis_result_keys": list(analysis_result.keys())
        })
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ì „ product_data ìƒíƒœ í™•ì¸
        log_debug(session_id, run_id, "H4", "test_crawler_report_consistency.py:main", "ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ì „ - product_data ìƒíƒœ", {
            "product_name": product_data.get("product_name", ""),
            "price_sale": product_data.get("price", {}).get("sale_price"),
            "price_original": product_data.get("price", {}).get("original_price"),
            "has_qpoint": bool(product_data.get("qpoint_info")),
            "return_policy": product_data.get("shipping_info", {}).get("return_policy")
        })
        
        checklist_result = await checklist_evaluator.evaluate_checklist(
            product_data=product_data,
            shop_data=None,
            analysis_result=analysis_result,
            page_structure=product_data.get("page_structure")
        )
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ê²°ê³¼ ë¡œê¹…
        log_debug(session_id, run_id, "H3", "test_crawler_report_consistency.py:main", "ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ì™„ë£Œ", {
            "overall_completion": checklist_result.get("overall_completion", 0),
            "checklist_count": len(checklist_result.get("checklists", [])),
            "completed_items": sum(
                len([item for item in cl.get("items", []) if item.get("status") == "completed"])
                for cl in checklist_result.get("checklists", [])
            ),
            "total_items": sum(
                len(cl.get("items", []))
                for cl in checklist_result.get("checklists", [])
            ),
            "checklist_categories": [cl.get("category") for cl in checklist_result.get("checklists", [])]
        })
        
        # ê° ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©ë³„ ìƒì„¸ ë¡œê¹…
        for checklist in checklist_result.get("checklists", []):
            category = checklist.get("category", "")
            for item in checklist.get("items", []):
                item_id = item.get("id", "")
                status = item.get("status", "")
                auto_checked = item.get("auto_checked", False)
                log_debug(session_id, run_id, "H5", "test_crawler_report_consistency.py:main", f"ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©: {item_id}", {
                    "category": category,
                    "title": item.get("title", ""),
                    "status": status,
                    "auto_checked": auto_checked,
                    "recommendation": item.get("recommendation", "")[:100] if item.get("recommendation") else ""
                })
        
        print(f"  âœ“ ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ì™„ë£Œ: ì „ì²´ ì™„ì„±ë„ {checklist_result.get('overall_completion', 0)}%")
        
        # ========== 4ë‹¨ê³„: ë¦¬í¬íŠ¸ ìƒì„± ==========
        print("\n[4ë‹¨ê³„] ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        report_generator = ReportGenerator()
        log_debug(session_id, run_id, "H3", "test_crawler_report_consistency.py:main", "ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", {
            "has_product_data": bool(product_data),
            "has_analysis_result": bool(analysis_result),
            "has_checklist_result": bool(checklist_result)
        })
        
        # ë¦¬í¬íŠ¸ ìƒì„± (Markdown í˜•ì‹)
        final_result = {
            "product_analysis": analysis_result,
            "checklist": checklist_result,
            "product_data": product_data
        }
        
        markdown_report = report_generator.generate_markdown_report(
            analysis_result=final_result,
            product_data=product_data,
            shop_data=None
        )
        
        log_debug(session_id, run_id, "H3", "test_crawler_report_consistency.py:main", "ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ", {
            "report_length": len(markdown_report),
            "has_checklist_in_report": "ì²´í¬ë¦¬ìŠ¤íŠ¸" in markdown_report or "checklist" in markdown_report.lower(),
            "has_product_info": "ìƒí’ˆ ì •ë³´" in markdown_report or "product" in markdown_report.lower()
        })
        
        print(f"  âœ“ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {len(markdown_report)} ë¬¸ì")
        
        # ========== 5ë‹¨ê³„: ë°ì´í„° ì¼ì¹˜ ì—¬ë¶€ ê²€ì¦ ==========
        print("\n[5ë‹¨ê³„] ë°ì´í„° ì¼ì¹˜ ì—¬ë¶€ ê²€ì¦ ì¤‘...")
        
        # ê²€ì¦ 1: í¬ë¡¤ëŸ¬ ë°ì´í„° â†’ ë¶„ì„ ê²°ê³¼ ì¼ì¹˜ ì—¬ë¶€
        inconsistencies = []
        
        # ê°€ê²© ì •ë³´ ì¼ì¹˜ ì—¬ë¶€
        crawler_price_sale = product_data.get("price", {}).get("sale_price")
        analysis_price_sale = analysis_result.get("price_analysis", {}).get("sale_price")
        if crawler_price_sale != analysis_price_sale:
            inconsistencies.append({
                "field": "price.sale_price",
                "crawler": crawler_price_sale,
                "analysis": analysis_price_sale,
                "hypothesis": "H2"
            })
        
        crawler_price_original = product_data.get("price", {}).get("original_price")
        analysis_price_original = analysis_result.get("price_analysis", {}).get("original_price")
        if crawler_price_original != analysis_price_original:
            inconsistencies.append({
                "field": "price.original_price",
                "crawler": crawler_price_original,
                "analysis": analysis_price_original,
                "hypothesis": "H2"
            })
        
        # ë¦¬ë·° ì •ë³´ ì¼ì¹˜ ì—¬ë¶€
        crawler_review_count = product_data.get("reviews", {}).get("review_count")
        analysis_review_count = analysis_result.get("review_analysis", {}).get("review_count")
        if crawler_review_count != analysis_review_count:
            inconsistencies.append({
                "field": "reviews.review_count",
                "crawler": crawler_review_count,
                "analysis": analysis_review_count,
                "hypothesis": "H2"
            })
        
        crawler_review_rating = product_data.get("reviews", {}).get("rating")
        analysis_review_rating = analysis_result.get("review_analysis", {}).get("rating")
        if crawler_review_rating != analysis_review_rating:
            inconsistencies.append({
                "field": "reviews.rating",
                "crawler": crawler_review_rating,
                "analysis": analysis_review_rating,
                "hypothesis": "H2"
            })
        
        # ê²€ì¦ 2: ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ì—ì„œ ì‚¬ìš©ëœ ë°ì´í„° í™•ì¸
        # item_001 (ìƒí’ˆ ë“±ë¡ ì™„ë£Œ) ì²´í¬
        item_001 = None
        for checklist in checklist_result.get("checklists", []):
            for item in checklist.get("items", []):
                if item.get("id") == "item_001":
                    item_001 = item
                    break
            if item_001:
                break
        
        if item_001:
            item_001_status = item_001.get("status")
            has_product_name = bool(product_data.get("product_name"))
            has_description = bool(product_data.get("description"))
            has_images = bool(product_data.get("images", {}).get("thumbnail") or product_data.get("images", {}).get("detail_images"))
            
            if item_001_status == "pending" and (has_product_name and has_description and has_images):
                inconsistencies.append({
                    "field": "checklist.item_001",
                    "issue": "ë°ì´í„°ê°€ ìˆëŠ”ë° ì²´í¬ë¦¬ìŠ¤íŠ¸ì—ì„œ pendingìœ¼ë¡œ í‘œì‹œë¨",
                    "crawler_has_name": has_product_name,
                    "crawler_has_description": has_description,
                    "crawler_has_images": has_images,
                    "checklist_status": item_001_status,
                    "hypothesis": "H1"
                })
        
        # item_004 (ê°€ê²© ì„¤ì • ì™„ë£Œ) ì²´í¬
        item_004 = None
        for checklist in checklist_result.get("checklists", []):
            for item in checklist.get("items", []):
                if item.get("id") == "item_004":
                    item_004 = item
                    break
            if item_004:
                break
        
        if item_004:
            item_004_status = item_004.get("status")
            has_price = bool(product_data.get("price", {}).get("sale_price"))
            
            if item_004_status == "pending" and has_price:
                inconsistencies.append({
                    "field": "checklist.item_004",
                    "issue": "ê°€ê²© ë°ì´í„°ê°€ ìˆëŠ”ë° ì²´í¬ë¦¬ìŠ¤íŠ¸ì—ì„œ pendingìœ¼ë¡œ í‘œì‹œë¨",
                    "crawler_has_price": has_price,
                    "checklist_status": item_004_status,
                    "hypothesis": "H1"
                })
        
        # ê²€ì¦ 3: ë¦¬í¬íŠ¸ì— ì²´í¬ë¦¬ìŠ¤íŠ¸ ë°˜ì˜ ì—¬ë¶€
        has_checklist_in_markdown = "ì²´í¬ë¦¬ìŠ¤íŠ¸" in markdown_report or "checklist" in markdown_report.lower()
        if not has_checklist_in_markdown:
            inconsistencies.append({
                "field": "report.checklist",
                "issue": "ë¦¬í¬íŠ¸ì— ì²´í¬ë¦¬ìŠ¤íŠ¸ ì •ë³´ê°€ í¬í•¨ë˜ì§€ ì•ŠìŒ",
                "hypothesis": "H5"
            })
        
        # ë¶ˆì¼ì¹˜ ì‚¬í•­ ë¡œê¹…
        log_debug(session_id, run_id, "RESULT", "test_crawler_report_consistency.py:main", "ë°ì´í„° ì¼ì¹˜ ê²€ì¦ ì™„ë£Œ", {
            "inconsistencies_count": len(inconsistencies),
            "inconsistencies": inconsistencies
        })
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ê²€ì¦ ê²°ê³¼")
        print("=" * 80)
        
        if inconsistencies:
            print(f"\nâŒ ë°œê²¬ëœ ë¶ˆì¼ì¹˜ ì‚¬í•­: {len(inconsistencies)}ê°œ\n")
            for i, inc in enumerate(inconsistencies, 1):
                print(f"{i}. [{inc.get('hypothesis', 'N/A')}] {inc.get('field', 'N/A')}")
                if 'issue' in inc:
                    print(f"   ë¬¸ì œ: {inc['issue']}")
                if 'crawler' in inc:
                    print(f"   í¬ë¡¤ëŸ¬ ê°’: {inc['crawler']}")
                if 'analysis' in inc:
                    print(f"   ë¶„ì„ ê°’: {inc['analysis']}")
                print()
        else:
            print("\nâœ… ëª¨ë“  ë°ì´í„°ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤!")
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        result_data = {
            "crawler_data": {
                "product_name": product_data.get("product_name"),
                "price": product_data.get("price"),
                "reviews": product_data.get("reviews"),
                "qpoint_info": product_data.get("qpoint_info"),
                "coupon_info": product_data.get("coupon_info"),
                "shipping_info": product_data.get("shipping_info")
            },
            "analysis_result": {
                "overall_score": analysis_result.get("overall_score"),
                "price_analysis": analysis_result.get("price_analysis"),
                "review_analysis": analysis_result.get("review_analysis")
            },
            "checklist_result": {
                "overall_completion": checklist_result.get("overall_completion"),
                "checklists": checklist_result.get("checklists")
            },
            "inconsistencies": inconsistencies
        }
        
        with open("test_consistency_result.json", "w", encoding="utf-8") as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ê°€ 'test_consistency_result.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        import traceback
        error_msg = str(e)
        traceback_str = traceback.format_exc()
        log_debug(session_id, run_id, "ERROR", "test_crawler_report_consistency.py:main", "ì—ëŸ¬ ë°œìƒ", {
            "error": error_msg,
            "traceback": traceback_str
        })
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {error_msg}")
        print(traceback_str)
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
